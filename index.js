// index.js
import express from "express";
import cors   from "cors";
import dotenv from "dotenv";
import fetch  from "node-fetch";     // npm install node-fetch
import { OpenAI } from "openai";     // npm install openai

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json({ limit: "10mb" }));

const openai      = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const assistantId = process.env.ASSISTANT_ID;
let   threadId    = null;

// ensure we only create one thread per server run
async function ensureThread() {
  if (!threadId) {
    console.log("â–¶ï¸ Creating new threadâ€¦");
    const t = await openai.beta.threads.create();
    threadId = t.id;
    console.log("ğŸ”– Thread ID:", threadId);
  }
  return threadId;
}

app.post("/chat", async (req, res) => {
  try {
    console.log("ğŸ“¬ /chat body:", req.body);
    const { message, fileUrl } = req.body;

    if (!message && !fileUrl) {
      return res.status(400).json({ error: "Need at least message or fileUrl." });
    }
    if (fileUrl) console.log("ğŸ”— Received fileUrl:", fileUrl);

    const tid = await ensureThread();

    // 1ï¸âƒ£ If there's a file URL, fetch it & upload to OpenAI
    if (fileUrl) {
      const resp = await fetch(fileUrl);
      if (!resp.ok) throw new Error(`Failed to fetch file: ${resp.status}`);
      const buffer = await resp.arrayBuffer();

      console.log("ğŸ“¤ Uploading file to OpenAIâ€¦");
      const up = await openai.files.create({
        file: Buffer.from(buffer),
        purpose: "vision"
      });
      console.log("âœ… Uploaded file ID:", up.id);

      // Tell the thread about the new file
      await openai.beta.threads.messages.create(tid, {
        role:    "user",
        content: "Hereâ€™s a file for you to analyse.",
        file_ids: [ up.id ],
      });
    }

    // 2ï¸âƒ£ Send any plainâ€text user message
    if (message) {
      console.log("âœ‰ï¸ Sending user message to thread:", message);
      await openai.beta.threads.messages.create(tid, {
        role:    "user",
        content: message
      });
    }

    // 3ï¸âƒ£ Run the assistant
    console.log("â–¶ï¸ Running assistantâ€¦");
    const run = await openai.beta.threads.runs.create(tid, {
      assistant_id: assistantId
    });

    // 4ï¸âƒ£ Poll until the run is done
    let status;
    do {
      await new Promise(r => setTimeout(r, 1000));
      status = await openai.beta.threads.runs.retrieve(tid, run.id);
      console.log("â€¦ status:", status.status);
    } while (status.status !== "completed");

    // 5ï¸âƒ£ Grab all messages & return the assistantâ€™s last one
    const msgs  = await openai.beta.threads.messages.list(tid);
    const reply = msgs.data
      .filter(m => m.role === "assistant")
      .map(m => m.content[0].text.value)
      .join("\n\n");
    console.log("ğŸ¤– Assistant reply:", reply);

    res.json({ reply });

  } catch (err) {
    console.error("âŒ Error in /chat:", err);
    res.status(500).json({ error: err.message });
  }
});

const port = process.env.PORT || 3000;
app.listen(port, () => {
  console.log(`ğŸš€ Server listening on port ${port}`);
});
